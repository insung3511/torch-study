{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "EPOCH = 200\n",
    "KERNEL_SIZE = 3\n",
    "POOLING_SIZE = 2\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "DATA_PATH = \"./pickle/\"\n",
    "DEVICE = torch.device(\"mps\")\n",
    "\n",
    "def list_to_list(input_list):\n",
    "    input_list_to_list = list(itertools.chain(*input_list))\n",
    "    return input_list_to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Read records file from  ./pickle/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 55.07it/s]\n"
     ]
    }
   ],
   "source": [
    "record_list = []\n",
    "pickle_input = dict()\n",
    "X, y = [], []\n",
    "\n",
    "print(\"[INFO] Read records file from \", DATA_PATH)\n",
    "with open(DATA_PATH + 'RECORDS') as f:\n",
    "    record_lines = f.readlines()\n",
    "\n",
    "for i in range(len(record_lines)):\n",
    "    record_list.append(str(record_lines[i].strip()))\n",
    "\n",
    "for i in tqdm(range(len(record_list))):\n",
    "    temp_path = DATA_PATH + \"mit\" + record_list[i] + \".pkl\"\n",
    "    with open(temp_path, 'rb') as f:\n",
    "        pickle_input = pickle.load(f)\n",
    "        for i in range(len(pickle_input[0])):\n",
    "            X.append(pickle_input[0][i])\n",
    "\n",
    "        for i in range(len(pickle_input[1])):\n",
    "            check_ann = pickle_input[1][i]\n",
    "            temp_ann_list = list()\n",
    "            if check_ann == \"N\":            # Normal\n",
    "                temp_ann_list.append(0)\n",
    "\n",
    "            elif check_ann == \"S\":          # Supra-ventricular\n",
    "                temp_ann_list.append(1)\n",
    "\n",
    "            elif check_ann == \"V\":          # Ventricular\n",
    "                temp_ann_list.append(2)\n",
    "\n",
    "            elif check_ann == \"F\":          # False alarm\n",
    "                temp_ann_list.append(3)\n",
    "\n",
    "            else:                           # Unclassed \n",
    "                temp_ann_list.append(4)\n",
    "            y.append(temp_ann_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.33, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.X = X_train\n",
    "        self.y = y_train\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = torch.FloatTensor(self.X[idx])\n",
    "        y = torch.FloatTensor(self.y[idx])\n",
    "        return X, y\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.X = X_test\n",
    "        self.y = y_test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = torch.FloatTensor(self.X[idx])\n",
    "        y = torch.FloatTensor(self.y[idx])\n",
    "        return X, y\n",
    "\n",
    "class ValidationDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.X = X_val\n",
    "        self.y = y_val\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = torch.FloatTensor(self.X[idx])\n",
    "        y = torch.FloatTensor(self.y[idx])\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset()\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = TestDataset()\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "validation_dataset = ValidationDataset()\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_conv1d           = nn.Conv1d(128, 32, 3)\n",
    "        self.input_bn               = nn.BatchNorm1d(426)\n",
    "        self.maxpooling             = nn.MaxPool1d(2, 2)\n",
    "\n",
    "        # LEFMS First\n",
    "        self.first_conv1d           = nn.Conv1d(32, 64, 3)\n",
    "        self.first_to_sec_conv1d    = nn.Conv1d(64, 64, 3)\n",
    "        self.first_bn               = nn.BatchNorm1d(422)\n",
    "        self.maxpooling             = nn.MaxPool1d(2, 2)\n",
    "\n",
    "        # LEFMS Second\n",
    "        self.second_conv1d          = nn.Conv1d(64, 64, 3)\n",
    "        self.sec_to_third_conv1d    = nn.Conv1d(64, 64, 3)\n",
    "        self.second_bn              = nn.BatchNorm1d(207)\n",
    "        self.maxpooling             = nn.MaxPool1d(2, 2)\n",
    "\n",
    "        # LEFMS third\n",
    "        self.third_conv1d           = nn.Conv1d(64, 128, 3)\n",
    "        self.third_to_fourth_conv1d = nn.Conv1d(128, 128, 3)\n",
    "        self.third_bn               = nn.BatchNorm1d(99)\n",
    "        self.maxpooling             = nn.MaxPool1d(2, 2)\n",
    "\n",
    "        # LEFMS fourth\n",
    "        self.fourth_conv1d          = nn.Conv1d(128, 128, 3)\n",
    "        self.fourth_to_fifth_conv1d = nn.Conv1d(128, 128, 3)\n",
    "        self.fourth_bn              = nn.BatchNorm1d(45)\n",
    "        self.maxpooling             = nn.MaxPool1d(2, 2)\n",
    "\n",
    "        # LEFMS fifth\n",
    "        self.fifth_conv1d           = nn.Conv1d(128, 256, 3)\n",
    "        self.fifth_to_sixth_conv1d  = nn.Conv1d(256, 256, 3)\n",
    "        self.fifth_bn               = nn.BatchNorm1d(18)\n",
    "        self.maxpooling             = nn.MaxPool1d(2, 2)\n",
    "\n",
    "        # LEFMS sixth\n",
    "        self.sixth_conv1d           = nn.Conv1d(256, 256, 3)\n",
    "        self.sixth_to_out_conv1d    = nn.Conv1d(256, 256, 3)\n",
    "        self.sixth_bn               = nn.BatchNorm1d(18)\n",
    "        self.maxpooling             = nn.MaxPool1d(2, 2)\n",
    "\n",
    "        # Output layter part\n",
    "        self.gru                    = nn.GRU(1536, 192)\n",
    "        self.fc                     = nn.Linear(1536, 192)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_conv1d(x)\n",
    "        x = self.input_bn(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.first_conv1d(x)\n",
    "        x = self.first_to_sec_conv1d(x)\n",
    "        x = self.first_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpooling(x)\n",
    "\n",
    "        x = self.second_conv1d(x)\n",
    "        x = self.sec_to_third_conv1d(x)\n",
    "        x = self.second_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpooling(x)\n",
    "\n",
    "        x = self.third_conv1d(x)\n",
    "        x = self.third_to_fourth_conv1d(x)\n",
    "        x = self.third_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpooling(x)\n",
    "\n",
    "        x = self.fourth_conv1d(x)\n",
    "        x = self.fourth_to_fifth_conv1d(x)\n",
    "        x = self.fourth_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpooling(x)\n",
    "        \n",
    "        x = self.fifth_conv1d(x)\n",
    "        x = self.fifth_to_sixth_conv1d(x)\n",
    "        x = self.sixth_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpooling(x)\n",
    "\n",
    "        x = self.sixth_conv1d(x)\n",
    "        x = self.sixth_to_out_conv1d(x)\n",
    "        x = self.sixth_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpooling(x)\n",
    "\n",
    "        x = torch.reshape(x, (-1, 1536))\n",
    "        x = F.dropout(x, training=self.training, p=0.5)\n",
    "        x = self.gru(x)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x, dim=5)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (input_conv1d): Conv1d(128, 32, kernel_size=(3,), stride=(1,))\n",
      "  (input_bn): BatchNorm1d(426, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (maxpooling): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (first_conv1d): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
      "  (first_to_sec_conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
      "  (first_bn): BatchNorm1d(422, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (second_conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
      "  (sec_to_third_conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
      "  (second_bn): BatchNorm1d(207, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (third_conv1d): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
      "  (third_to_fourth_conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  (third_bn): BatchNorm1d(99, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fourth_conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  (fourth_to_fifth_conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  (fourth_bn): BatchNorm1d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fifth_conv1d): Conv1d(128, 256, kernel_size=(3,), stride=(1,))\n",
      "  (fifth_to_sixth_conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
      "  (fifth_bn): BatchNorm1d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (sixth_conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
      "  (sixth_to_out_conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
      "  (sixth_bn): BatchNorm1d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru): GRU(1536, 192)\n",
      "  (fc): Linear(in_features=1536, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Model().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 5 elements not 18",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000011?line=30'>31</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m test_loss, test_accuracy\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000011?line=32'>33</a>\u001b[0m \u001b[39mfor\u001b[39;00m Epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, EPOCH \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000011?line=33'>34</a>\u001b[0m     train(model, train_dataloader, optimizer, log_interval\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000011?line=34'>35</a>\u001b[0m     test_loss, test_accuracy \u001b[39m=\u001b[39m evaluate(model, test_dataloader)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000011?line=35'>36</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m[EPOCH: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m], \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mTest Loss: \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mTest Accuracy: \u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(Epoch, test_loss, test_accuracy))\n",
      "\u001b[1;32m/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb Cell 8\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, log_interval)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000011?line=4'>5</a>\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000011?line=5'>6</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000011?line=6'>7</a>\u001b[0m output \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000011?line=7'>8</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, y)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000011?line=8'>9</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb Cell 8\u001b[0m in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000011?line=82'>83</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msixth_conv1d(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000011?line=83'>84</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msixth_to_out_conv1d(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000011?line=84'>85</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msixth_bn(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000011?line=85'>86</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000011?line=86'>87</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpooling(x)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    169\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    170\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    171\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    172\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    173\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    175\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    176\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    177\u001b[0m     bn_training,\n\u001b[1;32m    178\u001b[0m     exponential_average_factor,\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    180\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/nn/functional.py:2438\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2435\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m   2436\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> 2438\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   2439\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   2440\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 5 elements not 18"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{}({:.0f}%)]\\tTrain Loss: {:.6F}\".format(Epoch, batch_idx * len(x), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item()))\n",
    "        \n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            output = model(x)\n",
    "            test_loss += criterion(output, y).item()\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(y.view_as(prediction)).sum().item()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "for Epoch in range(1, EPOCH + 1):\n",
    "    train(model, train_dataloader, optimizer, log_interval=200)\n",
    "    test_loss, test_accuracy = evaluate(model, test_dataloader)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} %\\n\".format(Epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "155d6f2e0f64686ab4bfd14ea62d28fe51bc71031495ea0caf798feb858e6597"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
