{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "EPOCH = 200\n",
    "KERNEL_SIZE = 3\n",
    "POOLING_SIZE = 2\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "DATA_PATH = \"./pickle/\"\n",
    "DEVICE = torch.device(\"mps\")\n",
    "\n",
    "def list_to_list(input_list):\n",
    "    input_list_to_list = list(itertools.chain(*input_list))\n",
    "    return input_list_to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Read records file from  ./pickle/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:01<00:00, 45.80it/s]\n"
     ]
    }
   ],
   "source": [
    "record_list = []\n",
    "pickle_input = dict()\n",
    "X, y = [], []\n",
    "\n",
    "print(\"[INFO] Read records file from \", DATA_PATH)\n",
    "with open(DATA_PATH + 'RECORDS') as f:\n",
    "    record_lines = f.readlines()\n",
    "\n",
    "for i in range(len(record_lines)):\n",
    "    record_list.append(str(record_lines[i].strip()))\n",
    "\n",
    "for i in tqdm(range(len(record_list))):\n",
    "    temp_path = DATA_PATH + \"mit\" + record_list[i] + \".pkl\"\n",
    "    with open(temp_path, 'rb') as f:\n",
    "        pickle_input = pickle.load(f)\n",
    "        for i in range(len(pickle_input[0])):\n",
    "            X.append(pickle_input[0][i])\n",
    "\n",
    "        for i in range(len(pickle_input[1])):\n",
    "            check_ann = pickle_input[1][i]\n",
    "            temp_ann_list = list()\n",
    "            if check_ann == \"N\":            # Normal\n",
    "                temp_ann_list.append(0)\n",
    "\n",
    "            elif check_ann == \"S\":          # Supra-ventricular\n",
    "                temp_ann_list.append(1)\n",
    "\n",
    "            elif check_ann == \"V\":          # Ventricular\n",
    "                temp_ann_list.append(2)\n",
    "\n",
    "            elif check_ann == \"F\":          # False alarm\n",
    "                temp_ann_list.append(3)\n",
    "\n",
    "            else:                           # Unclassed \n",
    "                temp_ann_list.append(4)\n",
    "            y.append(temp_ann_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.33, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.X = X_train\n",
    "        self.y = y_train\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = torch.FloatTensor(self.X[idx])\n",
    "        y = torch.FloatTensor(self.y[idx])\n",
    "        return X, y\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.X = X_test\n",
    "        self.y = y_test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = torch.FloatTensor(self.X[idx])\n",
    "        y = torch.FloatTensor(self.y[idx])\n",
    "        return X, y\n",
    "\n",
    "class ValidationDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.X = X_val\n",
    "        self.y = y_val\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = torch.FloatTensor(self.X[idx])\n",
    "        y = torch.FloatTensor(self.y[idx])\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset()\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = TestDataset()\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "validation_dataset = ValidationDataset()\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_conv1d           = nn.Conv1d(128, 32, 3)\n",
    "        self.input_bn               = nn.BatchNorm1d(426)\n",
    "        self.maxpooling             = nn.MaxPool1d(2, 2)\n",
    "\n",
    "        # LEFMS First\n",
    "        self.first_conv1d           = nn.Conv1d(32, 64, 3)\n",
    "        self.first_to_sec_conv1d    = nn.Conv1d(64, 64, 3)\n",
    "        self.first_bn               = nn.BatchNorm1d(422)\n",
    "        self.maxpooling             = nn.MaxPool1d(2, 2)\n",
    "\n",
    "        # LEFMS Second\n",
    "        self.second_conv1d          = nn.Conv1d(64, 64, 3)\n",
    "        self.sec_to_third_conv1d    = nn.Conv1d(64, 64, 3)\n",
    "        self.second_bn              = nn.BatchNorm1d(207)\n",
    "        self.maxpooling             = nn.MaxPool1d(2, 2)\n",
    "\n",
    "        # LEFMS third\n",
    "        self.third_conv1d           = nn.Conv1d(64, 128, 3)\n",
    "        self.third_to_fourth_conv1d = nn.Conv1d(128, 128, 3)\n",
    "        self.third_bn               = nn.BatchNorm1d(99)\n",
    "        self.maxpooling             = nn.MaxPool1d(2, 2)\n",
    "\n",
    "        # LEFMS fourth\n",
    "        self.fourth_conv1d          = nn.Conv1d(128, 128, 3)\n",
    "        self.fourth_to_fifth_conv1d = nn.Conv1d(128, 128, 3)\n",
    "        self.fourth_bn              = nn.BatchNorm1d(45)\n",
    "        self.maxpooling             = nn.MaxPool1d(2, 2)\n",
    "\n",
    "        # LEFMS fifth\n",
    "        self.fifth_conv1d           = nn.Conv1d(128, 256, 3)\n",
    "        self.fifth_to_sixth_conv1d  = nn.Conv1d(256, 256, 3)\n",
    "        self.fifth_bn               = nn.BatchNorm1d(18)\n",
    "        self.maxpooling             = nn.MaxPool1d(2, 2)\n",
    "\n",
    "        # LEFMS sixth\n",
    "        self.sixth_conv1d           = nn.Conv1d(256, 256, 3)\n",
    "        self.sixth_to_out_conv1d    = nn.Conv1d(256, 256, 3)\n",
    "        self.sixth_bn               = nn.BatchNorm1d(5)\n",
    "        self.maxpooling             = nn.MaxPool1d(2, 2)\n",
    "\n",
    "        # Output layter part\n",
    "        self.gru                    = nn.GRU(512, 512)\n",
    "        self.fc1                    = nn.Linear(512, 192)\n",
    "        self.fc2                    = nn.Linear(192, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_conv1d(x)\n",
    "        x = self.input_bn(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.first_conv1d(x)\n",
    "        x = self.first_to_sec_conv1d(x)\n",
    "        x = self.first_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpooling(x)\n",
    "\n",
    "        x = self.second_conv1d(x)\n",
    "        x = self.sec_to_third_conv1d(x)\n",
    "        x = self.second_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpooling(x)\n",
    "\n",
    "        x = self.third_conv1d(x)\n",
    "        x = self.third_to_fourth_conv1d(x)\n",
    "        x = self.third_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpooling(x)\n",
    "\n",
    "        x = self.fourth_conv1d(x)\n",
    "        x = self.fourth_to_fifth_conv1d(x)\n",
    "        x = self.fourth_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpooling(x)\n",
    "        \n",
    "        x = self.fifth_conv1d(x)\n",
    "        x = self.fifth_to_sixth_conv1d(x)\n",
    "        x = self.fifth_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpooling(x)\n",
    "\n",
    "        x = self.sixth_conv1d(x)\n",
    "        x = self.sixth_to_out_conv1d(x)\n",
    "        x = self.sixth_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpooling(x)\n",
    "\n",
    "        x = torch.reshape(x, (-1, 512))\n",
    "        x = F.dropout(x, training=self.training, p=0.5)\n",
    "        x, _ = self.gru(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (input_conv1d): Conv1d(128, 32, kernel_size=(3,), stride=(1,))\n",
      "  (input_bn): BatchNorm1d(426, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (maxpooling): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (first_conv1d): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
      "  (first_to_sec_conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
      "  (first_bn): BatchNorm1d(422, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (second_conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
      "  (sec_to_third_conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
      "  (second_bn): BatchNorm1d(207, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (third_conv1d): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
      "  (third_to_fourth_conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  (third_bn): BatchNorm1d(99, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fourth_conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  (fourth_to_fifth_conv1d): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  (fourth_bn): BatchNorm1d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fifth_conv1d): Conv1d(128, 256, kernel_size=(3,), stride=(1,))\n",
      "  (fifth_to_sixth_conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
      "  (fifth_bn): BatchNorm1d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (sixth_conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
      "  (sixth_to_out_conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
      "  (sixth_bn): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru): GRU(512, 512)\n",
      "  (fc1): Linear(in_features=512, out_features=192, bias=True)\n",
      "  (fc2): Linear(in_features=192, out_features=128, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Model().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (x_data, y_data) in enumerate(train_loader):\n",
    "        x_data = x_data.to(DEVICE)\n",
    "        y_data = y_data.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_data).view(128, -1)\n",
    "\n",
    "        loss = criterion(output, y_data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{}({:.0f}%)]\\tTrain Loss: {:.6F}\".format(Epoch, batch_idx * len(x_data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item()))\n",
    "        \n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in validation_dataloader:\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            output = model(x)\n",
    "            test_loss += criterion(output, y).item()\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(y.view_as(prediction)).sum().item()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/75441(0%)]\tTrain Loss: -0.000000\n",
      "Train Epoch: 1 [25600/75441(34%)]\tTrain Loss: -0.000000\n",
      "Train Epoch: 1 [51200/75441(68%)]\tTrain Loss: -0.000000\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 128, 3], expected input[1, 49, 428] to have 128 channels, but got 49 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000008?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m Epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, EPOCH \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000008?line=1'>2</a>\u001b[0m     train(model, train_dataloader, optimizer, log_interval\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000008?line=2'>3</a>\u001b[0m     test_loss, test_accuracy \u001b[39m=\u001b[39m evaluate(model, test_dataloader)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000008?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m[EPOCH: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m], \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mTest Loss: \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mTest Accuracy: \u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(Epoch, test_loss, test_accuracy))\n",
      "\u001b[1;32m/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb Cell 9\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, log_interval)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000008?line=4'>5</a>\u001b[0m y_data \u001b[39m=\u001b[39m y_data\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000008?line=5'>6</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000008?line=6'>7</a>\u001b[0m output \u001b[39m=\u001b[39m model(x_data)\u001b[39m.\u001b[39mview(\u001b[39m128\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000008?line=8'>9</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, y_data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000008?line=9'>10</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb Cell 9\u001b[0m in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000008?line=48'>49</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000008?line=49'>50</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_conv1d(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000008?line=50'>51</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_bn(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bahk_insung/Documents/Github/torch-study/ecg/model.ipynb#ch0000008?line=51'>52</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/conv.py:307\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 307\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/conv.py:303\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    301\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    302\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 303\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    304\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 128, 3], expected input[1, 49, 428] to have 128 channels, but got 49 channels instead"
     ]
    }
   ],
   "source": [
    "for Epoch in range(1, EPOCH + 1):\n",
    "    train(model, train_dataloader, optimizer, log_interval=200)\n",
    "    test_loss, test_accuracy = evaluate(model, test_dataloader)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} %\\n\".format(Epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "155d6f2e0f64686ab4bfd14ea62d28fe51bc71031495ea0caf798feb858e6597"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
