{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bahk_insung/miniconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/bahk_insung/miniconda3/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <F0D48035-EF9E-3141-9F63-566920E60D7C> /Users/bahk_insung/miniconda3/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <44B645FB-F027-3EE5-86D7-DBF8E2FC6264> /Users/bahk_insung/miniconda3/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "device = torch.device('mps')\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLUSTER = 10\n",
    "LATENT_SIZE = 10\n",
    "DATASET_SHUFFLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset    = torchvision.datasets.MNIST('../data/', download=True, train=True, transform=transforms.ToTensor())\n",
    "testset    = torchvision.datasets.MNIST('../data/', download=True, train=False, transform=transforms.ToTensor())\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=DATASET_SHUFFLE)\n",
    "testloader  = DataLoader(testset,  batch_size=BATCH_SIZE, shuffle=DATASET_SHUFFLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        return x.view(batch_size, -1)\n",
    "\n",
    "class DeFlatten(nn.Module):\n",
    "    def __init__(self, k):\n",
    "        super(DeFlatten, self).__init__()\n",
    "        self.k  = k\n",
    "\n",
    "    def forward(self, x):\n",
    "        s = x.size()\n",
    "        feature_size = int((s[1] // self.k) ** 0.5)\n",
    "        return x.view(s[0], self.k, feature_size, feature_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kmeans(nn.Module):\n",
    "    def __init__(self, num_cluster, latent_size):\n",
    "        super(Kmeans, self).__init__()\n",
    "        device = torch.device(\"mps\")\n",
    "        self.num_cluster = num_cluster\n",
    "        self.centroids = nn.Parameter(torch.rand(\n",
    "            (self.num_cluster, latent_size)\n",
    "        ).to(device))\n",
    "\n",
    "    def argminl2distance(self, a, b):\n",
    "        return torch.argmin(\n",
    "            torch.sum((a - b) ** 2, dim=1), dim=0\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_assign = list()\n",
    "        for m in range(x.size(0)):\n",
    "            h = x[m].expand(self.num_cluster, -1)\n",
    "            assign = self.argminl2distance(h, self.centroids)\n",
    "            y_assign.append(assign.item())\n",
    "\n",
    "        return y_assign, self.centroids[y_assign]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.k = 16\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, self.k, 3, stride=2),                nn.ReLU(),\n",
    "            nn.Conv2d(self.k, 2 * self.k, 3, stride=2),       nn.ReLU(),\n",
    "            nn.Conv2d(2 * self.k, 4 * self.k, 3, stride=1),   nn.ReLU(),\n",
    "            Flatten(),\n",
    "            nn.Linear(1024, latent_size),           nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x) \n",
    "        # size = x.size()\n",
    "        # feature_size = int((size[1] // self.k) ** 0.5)\n",
    "        # return x.view(size[0], self.k, feature_size, feature_size)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        k = 16\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_size, 1024),           nn.ReLU(),\n",
    "            DeFlatten(4 * k),\n",
    "            nn.ConvTranspose2d(4 * k, 2 * k, 3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(2 * k, k, 3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(k, 1, 3, stride=2, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_acc(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    D = max(y_pred.max(), y_true.max()) + 1\n",
    "    w = np.zeros(\n",
    "        (D, D), dtype=np.int64\n",
    "    )\n",
    "\n",
    "    for i in range(len(y_pred.size)):\n",
    "        w[y_pred[i], y_true[i]] += 1\n",
    "\n",
    "    ind = linear_assignment(w.max() - w)\n",
    "    return sum([\n",
    "        w[i, j] for i, j in zip(ind[0], ind[1])\n",
    "    ]   * 1.0 / y_pred.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(testloader, encoder, kmeans, device):\n",
    "    predictions, actual = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            inputs = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            latent_var = encoder(inputs)\n",
    "            y_pred, _  = kmeans(latent_var)\n",
    "\n",
    "            predictions += y_pred\n",
    "            actual      += labels.cpu().tolist()\n",
    "    \n",
    "    return cluster_acc(actual, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(latent_size=LATENT_SIZE).to(device=device)\n",
    "decoder = Decoder(latent_size=LATENT_SIZE).to(device=device)\n",
    "kmeans  = Kmeans(num_cluster=NUM_CLUSTER, latent_size=LATENT_SIZE).to(device)\n",
    "\n",
    "criterion1 = torch.nn.MSELoss()\n",
    "criterion2 = torch.nn.MSELoss()\n",
    "optimizer  = torch.optim.Adam(\n",
    "    list(encoder.parameters()) + list(decoder.parameters()) + list(kmeans.parameters()),\n",
    "    lr=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = 50\n",
    "T2 = 200\n",
    "lam = 1e-3\n",
    "ls = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\tAverage loss : 0.07459391468464693\n",
      "Epoch : 1\tAverage loss : 0.04309159790529117\n",
      "\tEpoch 1 model has saved!\n",
      "Epoch : 2\tAverage loss : 0.03626011261569539\n",
      "\tEpoch 2 model has saved!\n",
      "Epoch : 3\tAverage loss : 0.03220169237459392\n",
      "\tEpoch 3 model has saved!\n",
      "Epoch : 4\tAverage loss : 0.02957155457787168\n",
      "\tEpoch 4 model has saved!\n",
      "Epoch : 5\tAverage loss : 0.027734393587530548\n",
      "\tEpoch 5 model has saved!\n"
     ]
    }
   ],
   "source": [
    "for ep in range(300):\n",
    "    if (ep > T1) and (ep < T2):\n",
    "        alpha = lam * (ep - T1) / (T2 - T1)\n",
    "    \n",
    "    elif ep >= T2:\n",
    "        alpha = lam\n",
    "\n",
    "    else:\n",
    "        # print()\n",
    "        alpha =lam / (T2-T1)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for images, _ in trainloader:\n",
    "        inputs = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        latent_var = encoder(inputs)\n",
    "        _, centroids = kmeans(latent_var.detach())\n",
    "        outputs = decoder(latent_var)\n",
    "\n",
    "        l_rec = criterion1(inputs, outputs)\n",
    "        l_clt = criterion2(latent_var, centroids)\n",
    "        loss = l_rec + alpha * l_clt\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(trainloader)\n",
    "    print(f\"Epoch : {ep}\\tAverage loss : {avg_loss}\")\n",
    "\n",
    "    if avg_loss < ls:\n",
    "        ls = avg_loss\n",
    "        torch.save(encoder.state_dict(), './models/dkm_en.pth')\n",
    "        torch.save(decoder.state_dict(), './models/dkm_de.pth')\n",
    "        torch.save(kmeans.state_dict(),  './models/dkm_clt.pth')\n",
    "        print(f\"\\tEpoch {ep} model has saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_state_dict(torch.load('./models/dkm_en.pth'))\n",
    "decoder.load_state_dict(torch.load('./models/dkm_de.pth'))\n",
    "kmeans.load_state_dict(torch.load('./models/dkm_clt.pth'))\n",
    "\n",
    "predicitions, actual, latent_features = [], [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        inputs = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        latent_var = encoder(inputs)\n",
    "        y_pred, _  = kmeans(latent_var)\n",
    "\n",
    "        predicitions += y_pred\n",
    "        latent_features += latent_var.cpu().tolist()\n",
    "        actual += labels.cpu().tolist()\n",
    "\n",
    "print(cluster_acc(actual, predicitions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbd03b52000256fffc5622fb1d5afa03ae770321afbfaac74e08013d54c137c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
