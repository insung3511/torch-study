{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla GAN (Generative Adversarial Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bahk_insung/miniconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/bahk_insung/miniconda3/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <F0D48035-EF9E-3141-9F63-566920E60D7C> /Users/bahk_insung/miniconda3/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <44B645FB-F027-3EE5-86D7-DBF8E2FC6264> /Users/bahk_insung/miniconda3/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "LEAKY_ReLU_VALUE = 0.2\n",
    "DROPOUT_VALUE = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform   = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5))])\n",
    "trainset    = FashionMNIST(root='../data/', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "device      = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.n_features = 128\n",
    "        self.n_out = 784\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(self.n_features, 256),        nn.LeakyReLU(LEAKY_ReLU_VALUE),\n",
    "            nn.Linear(256, 512),                    nn.LeakyReLU(LEAKY_ReLU_VALUE),\n",
    "            nn.Linear(512, 1024),                   nn.LeakyReLU(LEAKY_ReLU_VALUE),\n",
    "            nn.Linear(1024, self.n_out),            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.n_in = 784\n",
    "        self.n_out = 1\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(self.n_in, 1024),         nn.LeakyReLU(LEAKY_ReLU_VALUE), \n",
    "            nn.Dropout(DROPOUT_VALUE),\n",
    "            nn.Linear(1024, 512),               nn.LeakyReLU(LEAKY_ReLU_VALUE),\n",
    "            nn.Dropout(DROPOUT_VALUE),\n",
    "            nn.Linear(512, 256),                nn.LeakyReLU(LEAKY_ReLU_VALUE),\n",
    "            nn.Dropout(DROPOUT_VALUE),\n",
    "            nn.Linear(256, self.n_out),         nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        print(\"Discrimiatorr forward!\")\n",
    "        print(x.shape)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_optim = optim.Adam(generator.parameters(), lr=2e-4)\n",
    "d_optim = optim.Adam(discriminator.parameters(), lr=2e-4)\n",
    "\n",
    "g_losses, d_losses = list(), list()\n",
    "images = list()\n",
    "\n",
    "# BCE (BinaryCrossEntropy)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(n, n_features=128):\n",
    "    data = torch.randn(n, n_features)\n",
    "    return data\n",
    "\n",
    "def label_ones(size):\n",
    "    data = torch.ones(size, 1)\n",
    "    return data.to(device)\n",
    "\n",
    "def label_zeros(size):\n",
    "    data = torch.zeros(size, 1)\n",
    "    return data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(optimizer, dataReal, dataFake):\n",
    "    n = dataReal.size(0)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    predictionReal = discriminator(dataReal).to(device)\n",
    "    print(predictionReal.shape)\n",
    "    discriminatorLoss = criterion(predictionReal, label_ones(n)).to(device)\n",
    "\n",
    "    predictionFake = generator(dataFake).to(device)\n",
    "    print(predictionFake.shape)\n",
    "    generatorLoss = criterion(predictionFake, label_zeros(n)).to(device)\n",
    "    \n",
    "    print(discriminatorLoss.shape, generatorLoss.shape)\n",
    "    loss = discriminatorLoss + generatorLoss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def train_generator(optimizer, dataFake):\n",
    "    n = dataFake.size(0)\n",
    "    optimizer.zero_grad()\n",
    "    prediciton = discriminator(dataFake)\n",
    "    \n",
    "    loss = criterion(prediciton, label_ones(n))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrimiatorr forward!\n",
      "torch.Size([100, 784])\n",
      "torch.Size([100, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2800x28 and 128x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m dataFake \u001b[39m=\u001b[39m generator(noise(n))\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m dataReal \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 12\u001b[0m discriminatorLoss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m train_discriminator(d_optim, dataReal, dataFake)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m dataFake \u001b[39m=\u001b[39m generator(noise(n))\n\u001b[1;32m     14\u001b[0m generatorLoss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m train_generator(g_optim, dataFake)\n",
      "Cell \u001b[0;32mIn[98], line 9\u001b[0m, in \u001b[0;36mtrain_discriminator\u001b[0;34m(optimizer, dataReal, dataFake)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(predictionReal\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      7\u001b[0m discriminatorLoss \u001b[39m=\u001b[39m criterion(predictionReal, label_ones(n))\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> 9\u001b[0m predictionFake \u001b[39m=\u001b[39m generator(dataFake)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(predictionFake\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     11\u001b[0m generatorLoss \u001b[39m=\u001b[39m criterion(predictionFake, label_zeros(n))\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[93], line 14\u001b[0m, in \u001b[0;36mGenerator.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 14\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear(x)\n\u001b[1;32m     15\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m)\n\u001b[1;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2800x28 and 128x256)"
     ]
    }
   ],
   "source": [
    "noiseTest = noise(64)\n",
    "l = len(trainloader)\n",
    "for epoch in range(151):\n",
    "    generatorLoss, discriminatorLoss = 0.0, 0.0\n",
    "    for data in trainloader:\n",
    "        images, _ = data\n",
    "        n = len(images)\n",
    "        \n",
    "        dataFake = generator(noise(n)).detach().to(device)\n",
    "        dataReal = images.to(device)\n",
    "\n",
    "        discriminatorLoss += train_discriminator(d_optim, dataReal, dataFake).to(device)\n",
    "        dataFake = generator(noise(n))\n",
    "        generatorLoss += train_generator(g_optim, dataFake)\n",
    "\n",
    "    image = generator(noiseTest).detach().cpu()\n",
    "    image = make_grid(image)\n",
    "    images.append(image)\n",
    "\n",
    "    g_losses.append(generatorLoss / l)\n",
    "    d_losses.append(discriminatorLoss / l)\n",
    "    print(\"Epoch : {}. GenertorLoss : {:.3f}\\tDiscriminatorLoss : {:.3f}\\r\".format(epoch, generatorLoss / l, discriminatorLoss / l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbd03b52000256fffc5622fb1d5afa03ae770321afbfaac74e08013d54c137c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
